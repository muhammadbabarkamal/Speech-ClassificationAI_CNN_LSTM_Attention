#1.imports
import librosa
import matplotlib
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline  

import SpeechD
import SpeechGenerator
import SpeechModels



#2.Download and prepare all data
gscInfo, nCategs = SpeechD.PrepareGoogleSpeechCmd(version=2, task = 'leftright')
print(gscInfo.keys())
print(gscInfo['train'].keys())
print(len(gscInfo['train']['files']))
print(nCategs)


#3.speech data generator
sr=16000 #we know this one for google audios
iLen = 16000
trainGen = SpeechGenerator.SpeechGen(gscInfo['train']['files'], gscInfo['train']['labels'], shuffle=True)
#handle the fact that number of samples in validation may not be multiple of batch_size with shuffle=True
valGen   = SpeechGenerator.SpeechGen(gscInfo['val']['files'], gscInfo['val']['labels'], shuffle=True)
#use batch_size = total number of files to read all test files at once
testGen  = SpeechGenerator.SpeechGen(gscInfo['test']['files'], gscInfo['test']['labels'], shuffle=False, batch_size=len(gscInfo['test']['files']))
testRGen = SpeechGenerator.SpeechGen(gscInfo['testREAL']['files'], gscInfo['testREAL']['labels'], shuffle=False, batch_size=len(gscInfo['testREAL']['files']))
print(valGen.__len__())
print(testRGen.__len__())
print(testGen.__len__())
print(trainGen.__len__())




#4.checking
audios, classes = valGen.__getitem__(6)
classes


#5. model imports summery and compile

from keras.models import Model, load_model
from keras.layers import Input, Activation, Concatenate, Permute, Reshape, Flatten, Lambda, Dot, Softmax
from keras.layers import Add, Dropout, BatchNormalization, Conv2D, Reshape, MaxPooling2D, Dense, LSTM, Bidirectional
from keras import backend as K
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler
from keras import backend as K
from keras import optimizers
import SpeechModels

from kapre.time_frequency import Melspectrogram, Spectrogram
model = SpeechModels.RNNSpeechModel(3, samplingrate = 16000, inputLength = 16000)
model.summary()
model.compile(optimizer='adam', loss=['sparse_categorical_crossentropy'], metrics=['sparse_categorical_accuracy'])



#6a. saving model optional
model.save("model_name.h5")


#6b. Loading Model
from keras.models import Model, load_model
model.load_weights('model-attRNN.h5')



#7. learning rate setting
import math
from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler
def step_decay(epoch):
    initial_lrate = 0.001
    drop = 0.4
    epochs_drop = 15.0
    lrate = initial_lrate * math.pow(drop,  
            math.floor((1+epoch)/epochs_drop))
    
    if (lrate < 4e-5):
        lrate = 4e-5
      
    print('Changing learning rate to {}'.format(lrate))
    return lrate
lrate = LearningRateScheduler(step_decay)



#8.fir model and Run Epoches on model

from keras.models import Model, load_model

earlystopper = EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=10, verbose=1)
checkpointer = ModelCheckpoint('model_name.h5', monitor='val_sparse_categorical_accuracy', verbose=1, save_best_only=False)
results = model.fit_generator(trainGen, validation_data = valGen, epochs = 3, verbose=1,
callbacks=[earlystopper, checkpointer, lrate()])



#9.show results matlabpy
print(results.history)
# summarize history for categorical accuracy
plt.plot(results.history['sparse_categorical_accuracy'])
plt.plot(results.history['val_sparse_categorical_accuracy'])
plt.title('Categorical accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(results.history['loss'])
plt.plot(results.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()



#10.load best model according to cross-validation - model-attRNN
model = load_model('model_name.h5', custom_objects={'Melspectrogram': Melspectrogram, 'Normalization2D': Normalization2D })



#11. Read test data
x_test, y_test = testRGen.__getitem__(0)


#12. Results Evaluation
valEval = model.evaluate_generator(valGen, verbose=1)
trainEval = model.evaluate_generator(trainGen, verbose=1)
testEval = model.evaluate(x_test, y_test, verbose=1)
print('Evaluation scores: \nMetrics: {} \nTrain: {} \nValidation: {} \nTest: {}'.format(model.metrics_names, trainEval, valEval, testEval) )




#13. Predication on model

y_pred = model.predict(x_test, verbose=1)



#14. CONFUSION MATRIX

from sklearn.metrics import confusion_matrix
import audioUtils
cm = confusion_matrix(y_test, np.argmax(y_pred,1))
print(set(y_test))


#15. setting classes for Confusion matrix

#LRcmd
classes=['noise','left', 'right']

#16. plot confusion matrix

audioUtils.plot_confusion_matrix(cm,classes, normalize=True)




